import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import re  # í–‰ì •ë™ íŒŒì‹±ìš© ì •ê·œì‹
import pydeck as pdk

import requests  # ì§€ì˜¤ì½”ë”©ìš©
import time  #ì§€ì˜¤ì½”ë”© í˜¸ì¶œ ê°„ ê°„ê²© ì¡°ì ˆìš©
# ------------------------------------------------------------
# ê¸°ë³¸ ì„¤ì •
# ------------------------------------------------------------
st.set_page_config(
    page_title="CSC - í‰íƒì‹œ ëŒ€ê¸°ì§ˆ ë¦¬ìŠ¤í¬ & ë…¸ì¸ë³µì§€ì‹œì„¤ ë¶„ì„",
    layout="wide"
)

# ì‚¬ìš©ì PC/í´ë¼ìš°ë“œ ê¸°ì¤€ ë°ì´í„° í´ë”
BASE_DIR = (Path(__file__).parent / "data").resolve()

# QR ì½”ë“œ ì´ë¯¸ì§€ ê²½ë¡œ (csc_app.pyì™€ ê°™ì€ í´ë”ì— ì €ì¥í–ˆë‹¤ê³  ê°€ì •)
QR_PATH = Path(__file__).parent / "í‰íƒ ESG streamlit QR.png"

# ëŒ€ê¸°ì˜¤ì—¼ í•­ëª©ë³„ ì»¬ëŸ¼ëª… ë§¤í•‘
POLLUTANT_COLS = {
    "SO2": "ì´ì‚°í™”í™©ì¸¡ì •ê°’(ppm)",
    "NO2": "ì´ì‚°í™”ì§ˆì†Œì¸¡ì •ê°’(ppm)",
    "CO": "ì¼ì‚°í™”íƒ„ì†Œì¸¡ì •ê°’(ppm)",
    "O3": "ì˜¤ì¡´ì¸¡ì •ê°’(ppm)",
    "PM10": "PM10ì¸¡ì •ê°’(ã/ã¥)",
    "PM2.5": "PM25ì¸¡ì •ê°’(ã/ã¥)",
}

POLLUTANT_LABELS = {
    "SO2": "SOâ‚‚(ì´ì‚°í™”í™©)",
    "NO2": "NOâ‚‚(ì´ì‚°í™”ì§ˆì†Œ)",
    "CO": "CO(ì¼ì‚°í™”íƒ„ì†Œ)",
    "O3": "Oâ‚ƒ(ì˜¤ì¡´)",
    "PM10": "PM10(ë¯¸ì„¸ë¨¼ì§€)",
    "PM2.5": "PM2.5(ì´ˆë¯¸ì„¸ë¨¼ì§€)",
}

GRADE_TO_SCORE = {"ì¢‹ìŒ": 1, "ë³´í†µ": 2, "ë‚˜ì¨": 3, "ë§¤ìš°ë‚˜ì¨": 4}

# í‰íƒì‹œ ë²•ì •ë™ 23ê°œ (ë¹„ì „1Â·2ë™, ì‹ ì¥1Â·2ë™ í†µí•©)
LEGAL_EMD = [
    "íŒ½ì„±ì", "ì•ˆì¤‘ì", "í¬ìŠ¹ì", "ì²­ë¶ì",
    "ì§„ìœ„ë©´", "ì„œíƒ„ë©´", "ê³ ë•ë©´", "ì˜¤ì„±ë©´", "í˜„ë•ë©´",
    "ì¤‘ì•™ë™",
    "ì„œì •ë™", "ì†¡íƒ„ë™", "ì§€ì‚°ë™", "ì†¡ë¶ë™",
    "ì‹ ì¥ë™",   # ì‹ ì¥1Â·2ë™ í¬í•¨
    "ì‹ í‰ë™", "ì›í‰ë™", "í†µë³µë™",
    "ë¹„ì „ë™",   # ë¹„ì „1Â·2ë™ í¬í•¨
    "ì„¸êµë™", "ìš©ì´ë™", "ë™ì‚­ë™", "ê³ ë•ë™",
]

# ë™ ì´ë¦„ ë§¤í•‘ (ë¹„ì „1Â·2ë™ â†’ ë¹„ì „ë™, ì‹ ì¥1Â·2ë™ â†’ ì‹ ì¥ë™)
# ë™ ì´ë¦„ ë§¤í•‘ (ë¹„ì „1Â·2ë™ â†’ ë¹„ì „ë™, ì‹ ì¥1Â·2ë™ â†’ ì‹ ì¥ë™)
# ë™ ì´ë¦„ ë§¤í•‘ (ë¹„ì „1Â·2ë™, ì‹ ì¥1Â·2ë™ ì™¸ì— ì˜ˆì „ ë™ ì´ë¦„ê¹Œì§€ í¬í•¨)
EMD_ALIAS_MAP = {
    # ë¹„ì „ë™ ê³„ì—´
    "ë¹„ì „ë™": "ë¹„ì „ë™",
    "ë¹„ì „1ë™": "ë¹„ì „ë™",
    "ë¹„ì „ 1ë™": "ë¹„ì „ë™",
    "ë¹„ì „2ë™": "ë¹„ì „ë™",
    "ë¹„ì „ 2ë™": "ë¹„ì „ë™",
    # ì‹ ì¥ë™ ê³„ì—´
    "ì‹ ì¥ë™": "ì‹ ì¥ë™",
    "ì‹ ì¥1ë™": "ì‹ ì¥ë™",
    "ì‹ ì¥ 1ë™": "ì‹ ì¥ë™",
    "ì‹ ì¥2ë™": "ì‹ ì¥ë™",
    "ì‹ ì¥ 2ë™": "ì‹ ì¥ë™",
    # ì˜ˆì „ ë™ ì´ë¦„ â†’ í˜„ì¬ ë™ ì´ë¦„
    "ì´ì¶©ë™": "ì¤‘ì•™ë™",
    "í‰íƒë™": "ì›í‰ë™",
    "í•©ì •ë™": "ì‹ í‰ë™",
    "ì†Œì‚¬ë™": "ë¹„ì „ë™",
    "ìœ ì²œë™": "ì‹ í‰ë™",
    "ê°€ì¬ë™": "ì†¡íƒ„ë™",
    "ì¥ë‹¹ë™": "ì¤‘ì•™ë™",
    "ì¹ ê´´ë™": "ì†¡íƒ„ë™",
    "ì‹ ëŒ€ë™": "ì›í‰ë™",
}

# ë„ë¡œëª…ì£¼ì†Œ ì•ˆì˜ ì˜ˆì „ ë™ ì´ë¦„ì„ ìƒˆ ë™ ì´ë¦„ìœ¼ë¡œ ì¹˜í™˜ + ê´„í˜¸ ë‚´ìš© ì œê±°
OLD_DONG_IN_ADDR_MAP = {
    "ì´ì¶©ë™": "ì¤‘ì•™ë™",
    "í‰íƒë™": "ì›í‰ë™",
    "í•©ì •ë™": "ì‹ í‰ë™",
    "ì†Œì‚¬ë™": "ë¹„ì „ë™",
    "ìœ ì²œë™": "ì‹ í‰ë™",
    "ê°€ì¬ë™": "ì†¡íƒ„ë™",
    "ì¥ë‹¹ë™": "ì¤‘ì•™ë™",
    "ì¹ ê´´ë™": "ì†¡íƒ„ë™",
    "ì‹ ëŒ€ë™": "ì›í‰ë™",
}
# extract_eupmyeondong()ì—ì„œ ì‚¬ìš©í•  ì˜› ë™ì´ë¦„ â†’ í˜„ì¬ ë™ì´ë¦„ ë§¤í•‘
OLD_EMD_TO_NEW = OLD_DONG_IN_ADDR_MAP

def normalize_address_for_geocode(addr: str) -> str:
    """ì§€ì˜¤ì½”ë”©ì„ ìœ„í•œ ì£¼ì†Œ ì •ë¦¬ (ì˜› ë™ ì´ë¦„ â†’ í˜„ì¬ ë™ ì´ë¦„, ê´„í˜¸ ë‚´ìš© ì œê±° ë“±)."""
    if not addr or pd.isna(addr):
        return ""

    addr = str(addr)

    # 1) ì˜› ë™ ì´ë¦„ì´ ì£¼ì†Œ ë¬¸ìì—´ì— ì§ì ‘ ë“¤ì–´ê°€ ìˆìœ¼ë©´ í˜„ì¬ ë™ ì´ë¦„ìœ¼ë¡œ ì¹˜í™˜
    for old, new in OLD_DONG_IN_ADDR_MAP.items():
        if old in addr:
            addr = addr.replace(old, new)

    # 2) ê´„í˜¸ ì•ˆ ë‚´ìš©(ë™ ì´ë¦„ì´ë‚˜ ê±´ë¬¼ëª… ë“±)ì€ ì§€ì˜¤ì½”ë”©ì— ë°©í•´ê°€ ë˜ë¯€ë¡œ ì œê±°
    addr = re.sub(r"\(.*?\)", "", addr)

    # 3) ì‰¼í‘œ ë’¤(ì¸µ/í˜¸, ì§€ì¸µ ë“±) ì •ë³´ëŠ” ì§€ì˜¤ì½”ë”©ì— ê±°ì˜ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ì‰¼í‘œ ì•ê¹Œì§€ë§Œ ì‚¬ìš©
    addr = addr.split(",", 1)[0]

    # 4) ì–‘ìª½ ê³µë°± ì •ë¦¬
    addr = addr.strip()

    return addr


# ë„ë¡œëª…ì£¼ì†Œ ë¬¸ìì—´ ì•ˆì—ì„œë„ ê°™ì€ ì¹˜í™˜ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ dict
OLD_DONG_IN_ADDR = {
    old: new for old, new in EMD_ALIAS_MAP.items() if old != new
}
# ------------------------------------------------------------
# ìœ í‹¸ í•¨ìˆ˜
# ------------------------------------------------------------
@st.cache_data
def read_csv_safely(path: Path) -> pd.DataFrame:
    """ì¸ì½”ë”©ì„ ìë™ìœ¼ë¡œ ë§ì¶°ì„œ CSV ì½ê¸°."""
    for enc in ("utf-8-sig", "utf-8", "cp949"):
        try:
            return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError:
            continue
    return pd.read_csv(path, encoding="utf-8", errors="ignore")


@st.cache_data
def load_data():
    """í”„ë¡œì íŠ¸ì— ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ë°ì´í„° í•œ ë²ˆì— ë¡œë“œ."""
    air = read_csv_safely(BASE_DIR / "ê²½ê¸°ë„ëŒ€ê¸°í™˜ê²½ì •ë³´ì›”í‰ê· ìë£Œ.csv")
    grade = read_csv_safely(BASE_DIR / "ê²½ê¸°ë„_ëŒ€ê¸°í™˜ê²½ì •ë³´í•­ëª©ë³„ì§€ìˆ˜ë“±ê¸‰.csv")
    region = read_csv_safely(BASE_DIR / "ê²½ê¸°ë„_ëŒ€ê¸°í™˜ê²½_ì§„ë‹¨í‰ê°€ì‹œìŠ¤í…œ_ì§€ì—­ì •ë³´.csv")
    elderly = read_csv_safely(BASE_DIR / "ê²½ê¸°ë„_í‰íƒì‹œ_ë…¸ì¸ë³µì§€ì‹œì„¤_20250129_(1)_geocoded.csv")
    chem = read_csv_safely(BASE_DIR / "ê²½ê¸°ë„_í‰íƒì‹œ_ìœ í•´í™”í•™ë¬¼ì§ˆ_ì·¨ê¸‰ì‚¬ì—…ì¥_í˜„í™©_20250207.csv")
    cai = read_csv_safely(BASE_DIR / "pyeongtaek_CAI_index.csv")
    elderly_pop = read_csv_safely(
        BASE_DIR / "202504_202510_ì£¼ë¯¼ë“±ë¡ì¸êµ¬ê¸°íƒ€í˜„í™©(ê³ ë ¹ ì¸êµ¬í˜„í™©)_ì›”ê°„.csv"
    )
    return {
        "air": air,
        "grade": grade,
        "region": region,
        "elderly": elderly,
        "chem": chem,
        "elderly_pop": elderly_pop,
        "cai": cai,
    }


def add_air_quality_grades(df_air: pd.DataFrame,
                           df_grade: pd.DataFrame) -> pd.DataFrame:
    """ëŒ€ê¸°ì§ˆ ì›”í‰ê·  ë°ì´í„°ì— í•­ëª©ë³„ ë“±ê¸‰/ì ìˆ˜/ì¢…í•©ìœ„í—˜ì ìˆ˜ ì¶”ê°€."""
    df = df_air.copy()

    # ì¸¡ì •ì¼ì(YYYYMM)ë¥¼ ì‹¤ì œ ë‚ ì§œ(ë§¤ì›” 1ì¼)ë¡œ ë³€í™˜
    df["ì¸¡ì •ì¼"] = pd.to_datetime(df["ì¸¡ì •ì¼ì"].astype(str), format="%Y%m")

    # í•­ëª©ë³„ ë“±ê¸‰ ê¸°ì¤€ (í•­ëª©ëª… ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°)
    grade_info = df_grade.drop_duplicates("í•­ëª©ëª…", keep="first").set_index("í•­ëª©ëª…")

    def calc_grade(value: float, standard_row: pd.Series) -> str:
        if pd.isna(value):
            return np.nan
        if value <= standard_row["ì¢‹ìŒê¸°ì¤€"]:
            return "ì¢‹ìŒ"
        elif value <= standard_row["ë³´í†µê¸°ì¤€"]:
            return "ë³´í†µ"
        elif value <= standard_row["ë‚˜ì¨ê¸°ì¤€"]:
            return "ë‚˜ì¨"
        else:
            return "ë§¤ìš°ë‚˜ì¨"

    # ì˜¤ì—¼ë¬¼ì§ˆë³„ ë“±ê¸‰/ì ìˆ˜ ê³„ì‚°
    for pollutant, col_name in POLLUTANT_COLS.items():
        thresholds = grade_info.loc[pollutant]
        grade_col = f"{pollutant}_ë“±ê¸‰"
        score_col = f"{pollutant}_ì ìˆ˜"

        df[grade_col] = df[col_name].apply(lambda v: calc_grade(v, thresholds))
        df[score_col] = df[grade_col].map(GRADE_TO_SCORE)

    # ì¢…í•©ìœ„í—˜ì ìˆ˜: 6ê°œ í•­ëª© ì ìˆ˜ ì¤‘ ìµœëŒ“ê°’(=ê°€ì¥ ë‚˜ìœ ë“±ê¸‰)
    score_cols = [c for c in df.columns if c.endswith("_ì ìˆ˜")]
    df["ì¢…í•©ìœ„í—˜ì ìˆ˜"] = df[score_cols].max(axis=1)

    return df


def make_city_summary(df_air_scored: pd.DataFrame) -> pd.DataFrame:
    """ë„ì‹œë³„ í‰ê·  ë†ë„ / í‰ê·  ì¢…í•©ìœ„í—˜ì ìˆ˜ ìš”ì•½."""
    agg_cols = {
        "ì´ì‚°í™”í™©ì¸¡ì •ê°’(ppm)": "mean",
        "ì´ì‚°í™”ì§ˆì†Œì¸¡ì •ê°’(ppm)": "mean",
        "ì¼ì‚°í™”íƒ„ì†Œì¸¡ì •ê°’(ppm)": "mean",
        "ì˜¤ì¡´ì¸¡ì •ê°’(ppm)": "mean",
        "PM10ì¸¡ì •ê°’(ã/ã¥)": "mean",
        "PM25ì¸¡ì •ê°’(ã/ã¥)": "mean",
        "ì¢…í•©ìœ„í—˜ì ìˆ˜": "mean",
    }
    city_summary = (
        df_air_scored
        .groupby("ë„ì‹œëª…")
        .agg(agg_cols)
        .rename_axis("ë„ì‹œëª…")
        .reset_index()
    )
    return city_summary

# í–‰ì • ìÂ·ë©´Â·ë™ ì¶”ì¶œ : í‰íƒì‹œ ë²•ì • 25ê°œë§Œ í—ˆìš©
# í–‰ì • ìÂ·ë©´Â·ë™ë§Œ ë½‘ëŠ” í•¨ìˆ˜ (ê±´ë¬¼ë™ í•„í„°ë§ + ë¹„ì „/ì‹ ì¥ í†µí•©)
def extract_eupmyeondong(addr: str) -> str:
    if pd.isna(addr):
        return np.nan

    # ë¬¸ìì—´ë¡œ ë³€í™˜ í›„, ì˜› ë™ ì´ë¦„ì„ í˜„ì¬ ëª…ì¹­ìœ¼ë¡œ êµì²´
    text = str(addr)
    for old, new in OLD_EMD_TO_NEW.items():
        if old in text:
            text = text.replace(old, new)

    # 0ë‹¨ê³„: ì£¼ì†Œ ì „ì²´ì—ì„œ ë¹„ì „/ì‹ ì¥ ê³„ì—´ ë¨¼ì € ì²˜ë¦¬
    #   ì˜ˆ: "ë¹„ì „1ë™ 123-4", "ì‹ ì¥ 2ë™ 11-3" ë“±
    for key, canon in EMD_ALIAS_MAP.items():
        if key in text:
            return canon

    # 1ë‹¨ê³„: ë‚˜ë¨¸ì§€ëŠ” ê¸°ì¡´ ë¡œì§ëŒ€ë¡œ í† í° ë‹¨ìœ„ í•„í„°ë§
    tokens = re.split(r"[ ,()]", text)

    for tok in tokens:
        tok = tok.strip()
        if not tok:
            continue

        # ì/ë©´/ë™ìœ¼ë¡œ ëë‚˜ì§€ ì•Šìœ¼ë©´ íŒ¨ìŠ¤
        if not tok.endswith(("ì", "ë©´", "ë™")):
            continue

        # ê´‘ì—­/ê¸°ì´ˆ ì§€ìì²´ ì´ë¦„ ì œì™¸
        if tok in ("ê²½ê¸°ë„", "í‰íƒì‹œ"):
            continue

        # ìˆ«ì + ë™ (1ë™, 103ë™ ë“±) â†’ ê±´ë¬¼ë™
        if re.fullmatch(r"\d+ë™", tok):
            continue

        # ì˜ë¬¸/ìˆ«ì ì½”ë“œ + ë™ (Aë™, Bë™, S001ë™ ë“±) â†’ ê±´ë¬¼ë™
        if re.fullmatch(r"[A-Za-z0-9]+ë™", tok):
            continue

        # ì œ1ë™, ì œ2ë™ í˜•íƒœ â†’ ê±´ë¬¼ë™
        if re.fullmatch(r"ì œ\d+ë™", tok):
            continue

        # ìƒê°€ë™ ê´€ë ¨ â†’ ê±´ë¬¼ë™
        if "ìƒê°€ë™" in tok or (tok.startswith("ìƒê°€") and tok.endswith("ë™")):
            continue

        # í•œ ê¸€ì + ë™ (ê°€ë™, ë‚˜ë™ ë“±) â†’ ê±´ë¬¼ë™
        if len(tok) == 2 and tok.endswith("ë™"):
            continue

        # ë¹„ì „1ë™/ì‹ ì¥1ë™ ë“±ì´ í† í°ìœ¼ë¡œ ë“¤ì–´ì˜¨ ê²½ìš°ë¥¼ ì •ê·œí™”
        norm = EMD_ALIAS_MAP.get(tok, tok)

        # 23ê°œ ë²•ì •ë™ ì•ˆì— ë“¤ì–´ê°€ëŠ” ê²ƒë§Œ ì¸ì •
        if norm in LEGAL_EMD:
            return norm

    return np.nan


# ------------------------------------------------------------
# ë…¸ì¸ë³µì§€ì‹œì„¤ ë„ë¡œëª…ì£¼ì†Œ ì§€ì˜¤ì½”ë”© (OpenStreetMap Nominatim ì˜ˆì‹œ)
# ------------------------------------------------------------
def _geocode_single(addr: str):
    """ë‹¨ì¼ ì£¼ì†Œë¥¼ ìœ„ë„/ê²½ë„ë¡œ ë³€í™˜ (ì‹¤íŒ¨í•˜ë©´ (None, None) ë°˜í™˜)."""
    if not addr or pd.isna(addr):
        return None, None

    # ----- 1) ì˜› ë™ ì´ë¦„ì„ í˜„ì¬ ë™ ì´ë¦„ìœ¼ë¡œ ì¹˜í™˜ -----
    addr_norm = str(addr)
    for old, new in OLD_DONG_IN_ADDR.items():
        if old in addr_norm:
            addr_norm = addr_norm.replace(old, new)

    query = normalize_address_for_geocode(addr)

    # ----- 2) OSM Nominatim í˜¸ì¶œ -----
    url = "https://nominatim.openstreetmap.org/search"
    params = {
        "q": query,
        "format": "json",
        "limit": 1,
    }
    headers = {
        # OSM ì •ì±…ìƒ user-agent ê¼­ í•„ìš”. ì´ë©”ì¼ì€ í¸í•œ ê±¸ë¡œ ë°”ê¿”ë„ ë¨.
        "User-Agent": "pyeongtaek-esg-app (contact: your_email@example.com)"
    }

    try:
        r = requests.get(url, params=params, headers=headers, timeout=5)
        r.raise_for_status()
        data = r.json()
        if not data:
            return None, None
        return float(data[0]["lat"]), float(data[0]["lon"])
    except Exception:
        return None, None




@st.cache_data
def geocode_elderly_addresses(addresses: tuple) -> pd.DataFrame:
    """
    ë…¸ì¸ë³µì§€ì‹œì„¤ ë„ë¡œëª…ì£¼ì†Œ ëª©ë¡ì„ ë°›ì•„ ì§€ì˜¤ì½”ë”© ê²°ê³¼(lat, lon)ë¥¼ ë°˜í™˜.
    ê°™ì€ ì£¼ì†Œ ì„¸íŠ¸ì— ëŒ€í•´ì„œëŠ” ìºì‹œë˜ì–´ ë‹¤ì‹œ í˜¸ì¶œë˜ì§€ ì•ŠìŒ.
    """
    rows = []
    for addr in addresses:
        lat, lon = _geocode_single(addr)
        rows.append({"ë„ë¡œëª…ì£¼ì†Œ": addr, "ìœ„ë„": lat, "ê²½ë„": lon})
        # ë„ˆë¬´ ê³µê²©ì ìœ¼ë¡œ í˜¸ì¶œí•˜ë©´ ë§‰í ìˆ˜ ìˆìœ¼ë‹ˆ ì•½ê°„ì˜ ê°„ê²©
        time.sleep(0.3)
    return pd.DataFrame(rows)



def ensure_elderly_geocoded(df_elderly: pd.DataFrame) -> pd.DataFrame:
    """
    ë…¸ì¸ë³µì§€ì‹œì„¤ ë°ì´í„°ì— ëŒ€í•´ ë„ë¡œëª…ì£¼ì†Œ ê¸°ì¤€ìœ¼ë¡œ ì§€ì˜¤ì½”ë”©ì„ ìˆ˜í–‰í•˜ì—¬
    ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ì„ ì±„ì›Œì¤€ë‹¤.
    - CSVì— lat/lon ì»¬ëŸ¼ì´ ì´ë¯¸ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ìœ„ë„/ê²½ë„ë¡œ ì‚¬ìš©í•˜ê³ ,
      ë¶€ì¡±í•œ í–‰ë§Œ ì¶”ê°€ë¡œ ì§€ì˜¤ì½”ë”©í•œë‹¤.
    """
    df = df_elderly.copy()

    # 0) _geocoded.csvì— lat / lon ìœ¼ë¡œ ì €ì¥ëœ ê²½ìš°ë¥¼ ë¨¼ì € ì²˜ë¦¬
    if "lat" in df.columns and "ìœ„ë„" not in df.columns:
        df.rename(columns={"lat": "ìœ„ë„"}, inplace=True)
    if "lon" in df.columns and "ê²½ë„" not in df.columns:
        df.rename(columns={"lon": "ê²½ë„"}, inplace=True)

    # 1) ìœ„ë„/ê²½ë„ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒì„±
    if "ìœ„ë„" not in df.columns:
        df["ìœ„ë„"] = np.nan
    if "ê²½ë„" not in df.columns:
        df["ê²½ë„"] = np.nan

    # 2) ì§€ì˜¤ì½”ë”©ì´ í•„ìš”í•œ í–‰(ìœ„ë„ ë˜ëŠ” ê²½ë„ê°€ ë¹„ì–´ ìˆëŠ” ê²½ìš°)ë§Œ ëŒ€ìƒìœ¼ë¡œ
    need_geo_mask = df["ìœ„ë„"].isna() | df["ê²½ë„"].isna()
    addrs_to_geo = (
        df.loc[need_geo_mask, "ë„ë¡œëª…ì£¼ì†Œ"]
        .dropna()
        .unique()
        .tolist()
    )

    if not addrs_to_geo:
        # ì´ë¯¸ ì „ë¶€ ì±„ì›Œì ¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return df

    addr_tuple = tuple(sorted(addrs_to_geo))

    with st.spinner("ë…¸ì¸ë³µì§€ì‹œì„¤ ë„ë¡œëª…ì£¼ì†Œë¥¼ ì§€ì˜¤ì½”ë”©í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. (í•œ ë²ˆë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤)"):
        geo_df = geocode_elderly_addresses(addr_tuple)

    # 3) ê¸°ì¡´ dfì™€ ì§€ì˜¤ì½”ë”© ê²°ê³¼ë¥¼ ë³‘í•©
    df = df.merge(geo_df, on="ë„ë¡œëª…ì£¼ì†Œ", how="left", suffixes=("", "_geo"))

    # ê¸°ì¡´ ìœ„ë„/ê²½ë„ê°€ ë¹„ì–´ ìˆëŠ” ê²½ìš°ì—ë§Œ _geo ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
    for col in ["ìœ„ë„", "ê²½ë„"]:
        geo_col = f"{col}_geo"
        if geo_col in df.columns:
            df[col] = df[col].where(~df[col].isna(), df[geo_col])
            df.drop(columns=[geo_col], inplace=True)
    # 4) ì•„ì§ë„ ì¢Œí‘œê°€ ì—†ëŠ” í–‰ì€ 'í–‰ì •ë™ ì¤‘ì‹¬ì 'ìœ¼ë¡œ ë³´ì •
    if "í–‰ì •ë™" in df.columns:
        # ì¢Œí‘œê°€ ìˆëŠ” ì‹œì„¤ë“¤ë§Œ ì´ìš©í•´ì„œ í–‰ì •ë™ë³„ í‰ê·  ì¢Œí‘œ ê³„ì‚°
        emd_centers = (
            df.dropna(subset=["ìœ„ë„", "ê²½ë„"])
              .groupby("í–‰ì •ë™")[["ìœ„ë„", "ê²½ë„"]]
              .mean()
        )

        if not emd_centers.empty:
            def fill_with_center(row):
                if (pd.isna(row["ìœ„ë„"]) or pd.isna(row["ê²½ë„"])):
                    emd = row.get("í–‰ì •ë™")
                    if emd in emd_centers.index:
                        center = emd_centers.loc[emd]
                        row["ìœ„ë„"] = center["ìœ„ë„"]
                        row["ê²½ë„"] = center["ê²½ë„"]
                return row

            df = df.apply(fill_with_center, axis=1)

    return df



# ------------------------------------------------------------
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# ------------------------------------------------------------
def main():
    st.title("CSC í”„ë¡œì íŠ¸ - ê³µê³µ ESG ê´€ì  í‰íƒì‹œ ëŒ€ê¸°ì§ˆ ë¦¬ìŠ¤í¬ & ë…¸ì¸ë³µì§€ì‹œì„¤ ë¶„ì„")

    # Streamlit ëŒ€ì‹œë³´ë“œ QR ì½”ë“œ (ì œëª© ì•„ë˜, ë°ì´í„° ì¶œì²˜ ìœ„)
    qr_path = Path(__file__).parent / "í‰íƒ ESG streamlit QR.png"
    if qr_path.exists():
        st.image(
            str(qr_path),
            width=180,
            caption="ëª¨ë°”ì¼ì—ì„œ ì—´ì–´ë³´ê¸° (Streamlit ëŒ€ì‹œë³´ë“œ QR)",
        )

    st.caption(
        "ë°ì´í„° ì¶œì²˜: ê³µê³µë°ì´í„°í¬í„¸(data.go.kr) - "
        "ê²½ê¸°ë„ ëŒ€ê¸°í™˜ê²½ì •ë³´, í‰íƒì‹œ ë…¸ì¸ë³µì§€ì‹œì„¤, ìœ í•´í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰ì‚¬ì—…ì¥, "
        "ê²½ê¸°ë„ ëŒ€ê¸°í™˜ê²½ ì§„ë‹¨í‰ê°€ì‹œìŠ¤í…œ ì§€ì—­ì •ë³´, ì£¼ë¯¼ë“±ë¡ì¸êµ¬(ê³ ë ¹ ì¸êµ¬í˜„í™©)"
    )


    # ë°ì´í„° ë¡œë“œ
    data = load_data()
    df_air_raw = data["air"]
    df_grade = data["grade"]
    df_region = data["region"]
    df_elderly_raw = data["elderly"]
    df_chem = data["chem"]
    df_pop = data["elderly_pop"]
    df_cai = data["cai"]

    df_elderly_raw = df_elderly_raw.copy()
    df_elderly_raw["í–‰ì •ë™"] = df_elderly_raw["ë„ë¡œëª…ì£¼ì†Œ"].apply(extract_eupmyeondong)


    # ë…¸ì¸ë³µì§€ì‹œì„¤: ë„ë¡œëª…ì£¼ì†Œ ì§€ì˜¤ì½”ë”© ì ìš©
    df_elderly = ensure_elderly_geocoded(df_elderly_raw)

    # ì „ì²˜ë¦¬ (ëŒ€ê¸°ì§ˆ ë“±ê¸‰/ìœ„í—˜ì ìˆ˜ ê³„ì‚°)
    df_air = add_air_quality_grades(df_air_raw, df_grade)
    city_summary = make_city_summary(df_air)

    # ğŸ‘‰ í‰íƒì‹œ ì¢…í•©ìœ„í—˜ì ìˆ˜ëŠ” CAI íŒŒì¼ ê°’ìœ¼ë¡œ ëŒ€ì²´
    # pyeongtaek_CAI_index.csv : ìÂ·ë©´Â·ë™ë³„ CAI_Index (ì´ë¯¸ ì¢…í•© ìœ„í—˜ì§€ìˆ˜ë¡œ ê³„ì‚°ëœ ê°’)
    if "CAI_Index" in df_cai.columns:
        # í‰íƒì‹œ 23ê°œ ìÂ·ë©´Â·ë™ CAI_Indexì˜ í‰ê· ì„ 'í‰íƒì‹œ ì¢…í•©ìœ„í—˜ì ìˆ˜'ë¡œ ì‚¬ìš©
        pyeongtaek_cai_mean = df_cai["CAI_Index"].mean()
        city_summary.loc[
            city_summary["ë„ì‹œëª…"] == "í‰íƒì‹œ", "ì¢…í•©ìœ„í—˜ì ìˆ˜"
        ] = pyeongtaek_cai_mean

    # í‰íƒì‹œ/ê²½ê¸°ë„ í‰ê·  ìœ„í—˜ ì ìˆ˜ (ìœ„ ì½”ë“œì—ì„œ í‰íƒì‹œ ê°’ ì´ë¯¸ êµì²´ë¨)
    pyeongtaek_row = city_summary[city_summary["ë„ì‹œëª…"] == "í‰íƒì‹œ"].iloc[0]
    gyeonggi_mean_risk = city_summary["ì¢…í•©ìœ„í—˜ì ìˆ˜"].mean()
    pyeongtaek_risk = pyeongtaek_row["ì¢…í•©ìœ„í—˜ì ìˆ˜"]

    # í‰íƒì‹œ ê¸°ì´ˆ ì •ë³´ (ëŒ€ê¸°í™˜ê²½ ì§„ë‹¨í‰ê°€ì‹œìŠ¤í…œ)
    region_row = df_region[df_region["ì‹œêµ°êµ¬ëª…"] == "í‰íƒì‹œ"].iloc[0]

    # í‰íƒì‹œ ë‚´ë¶€ ìÂ·ë©´Â·ë™ ë‹¨ìœ„ 'ìœ„í—˜ì§€ìˆ˜' ê³„ì‚°
    # ë…¸ì¸ë³µì§€ì‹œì„¤: ë„ë¡œëª…ì£¼ì†Œ ì‚¬ìš©
    # ë…¸ì¸ë³µì§€ì‹œì„¤: ë„ë¡œëª…ì£¼ì†Œ ì‚¬ìš©
    df_elderly["í–‰ì •ë™"] = df_elderly["ë„ë¡œëª…ì£¼ì†Œ"].apply(extract_eupmyeondong)

    # ìœ í•´í™”í•™ë¬¼ì§ˆ ì‚¬ì—…ì¥: ë„ë¡œëª…ì£¼ì†Œ â†’ ì•ˆ ë‚˜ì˜¤ë©´ ì§€ë²ˆì£¼ì†Œë¡œ ë³´ì™„
    df_chem["í–‰ì •ë™"] = df_chem["ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"].apply(extract_eupmyeondong)
    mask_na = df_chem["í–‰ì •ë™"].isna()
    if "ì†Œì¬ì§€ì§€ë²ˆì£¼ì†Œ" in df_chem.columns:
        df_chem.loc[mask_na, "í–‰ì •ë™"] = df_chem.loc[mask_na, "ì†Œì¬ì§€ì§€ë²ˆì£¼ì†Œ"].apply(
            extract_eupmyeondong
        )

    # ğŸ‘‰ í‰íƒì‹œ ë²•ì •ë™ 23ê°œ ê¸°ì¤€ìœ¼ë¡œ ê°•ì œ ì •ë ¬/ì±„ì›€
    emd_index = pd.Index(LEGAL_EMD, name="í–‰ì •ë™")

    elderly_cnt = (
        df_elderly.groupby("í–‰ì •ë™")
        .size()
        .rename("ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜")
    )
    chem_cnt = (
        df_chem.groupby("í–‰ì •ë™")
        .size()
        .rename("ìœ í•´í™”í•™ì‚¬ì—…ì¥_ìˆ˜")
    )

    # 0ë‹¨ê³„: ê¸°ë³¸ ì§‘ê³„ (ì‹œì„¤ ìˆ˜)
    local_risk = (
        pd.concat([elderly_cnt, chem_cnt], axis=1)
        .reindex(emd_index)   # â† 23ê°œ ë™ìœ¼ë¡œ ì¬ì •ë ¬ + ì—†ëŠ” ë™ì€ 0ìœ¼ë¡œ
        .fillna(0)
    )

    local_risk["ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜"] = local_risk["ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜"].astype(int)
    local_risk["ìœ í•´í™”í•™ì‚¬ì—…ì¥_ìˆ˜"] = local_risk["ìœ í•´í™”í•™ì‚¬ì—…ì¥_ìˆ˜"].astype(int)

    # 1ë‹¨ê³„: CAI íŒŒì¼ì—ì„œ 'ëŒ€ê¸°ì§ˆ ìœ„í—˜ ì§€ìˆ˜' ê°€ì ¸ì˜¤ê¸°
    # pyeongtaek_CAI_index.csv : [ìë©´ë™, CAI_Index, CAI_ë“±ê¸‰]
    cai_index = df_cai.set_index("ìë©´ë™")
    local_risk = local_risk.join(cai_index[["CAI_Index"]], how="left")

    # CAI_Indexë¥¼ 'ëŒ€ê¸°ì§ˆìœ„í—˜ì§€ìˆ˜'ë¡œ ì‚¬ìš©
    local_risk = local_risk.rename(columns={"CAI_Index": "ëŒ€ê¸°ì§ˆìœ„í—˜ì§€ìˆ˜"})

    # 2ë‹¨ê³„: ìµœì¢… ìœ„í—˜ ì§€ìˆ˜ = 0.3 * ìœ í•´í™”í•™ì‚¬ì—…ì¥ ìˆ˜ + 0.7 * ëŒ€ê¸°ì§ˆ ìœ„í—˜ ì§€ìˆ˜
    local_risk["ìœ„í—˜ì§€ìˆ˜"] = (
        0.3 * local_risk["ìœ í•´í™”í•™ì‚¬ì—…ì¥_ìˆ˜"]
        + 0.7 * local_risk["ëŒ€ê¸°ì§ˆìœ„í—˜ì§€ìˆ˜"]
    )

    # ìµœì¢… ìœ„í—˜ ì§€ìˆ˜ ê¸°ì¤€ ì •ë ¬
    local_risk = local_risk.sort_values("ìœ„í—˜ì§€ìˆ˜", ascending=False)

    # ìÂ·ë©´Â·ë™ë³„ í‰ê·  ì¢Œí‘œ (ë…¸ì¸ë³µì§€ì‹œì„¤ + ìœ í•´í™”í•™ì‚¬ì—…ì¥ ëª¨ë‘ í™œìš©)
    coords_list = []
    if {"ìœ„ë„", "ê²½ë„"}.issubset(df_elderly.columns):
        elder_coords_all = (
            df_elderly.dropna(subset=["ìœ„ë„", "ê²½ë„"])
            .groupby("í–‰ì •ë™")[["ìœ„ë„", "ê²½ë„"]]
            .mean()
        )
        coords_list.append(elder_coords_all)

    if {"ìœ„ë„", "ê²½ë„"}.issubset(df_chem.columns):
        chem_coords = (
            df_chem.dropna(subset=["ìœ„ë„", "ê²½ë„"])
            .groupby("í–‰ì •ë™")[["ìœ„ë„", "ê²½ë„"]]
            .mean()
        )
        coords_list.append(chem_coords)

    if coords_list:
        coords_all = (
            pd.concat(coords_list)
            .groupby("í–‰ì •ë™")[["ìœ„ë„", "ê²½ë„"]]
            .mean()
        )
        local_risk_map = local_risk.join(coords_all, how="left")
    else:
        coords_all = pd.DataFrame()
        local_risk_map = local_risk.copy()

    # ì£¼ë¯¼ë“±ë¡ ì¸êµ¬(ê³ ë ¹ ì¸êµ¬) - í‰íƒì‹œ ìÂ·ë©´Â·ë™ë³„ 65ì„¸ ì´ìƒ ì¸êµ¬
    df_pop_pt = df_pop[df_pop["í–‰ì •êµ¬ì—­"].str.contains("í‰íƒì‹œ", na=False)].copy()
    df_pop_pt["ìë©´ë™"] = df_pop_pt["í–‰ì •êµ¬ì—­"].apply(extract_eupmyeondong)
    df_pop_pt = df_pop_pt[~df_pop_pt["ìë©´ë™"].isna()].copy()

    aged_total_cols = [c for c in df_pop_pt.columns if "65ì„¸ì´ìƒì „ì²´" in c]
    aged_total_cols = sorted(aged_total_cols)
    default_month_idx = len(aged_total_cols) - 1 if aged_total_cols else 0

    # --------------------------------------------------------
    # íƒ­ êµ¬ì„±
    # --------------------------------------------------------
    tabs = st.tabs([
        "1. ë°ì´í„° ê°œìš”",
        "2. ëŒ€ê¸°ì§ˆ ë¶„ì„ (ê²½ê¸°ë„ vs í‰íƒì‹œ)",
        "3. í‰íƒì‹œ ìœ í•´í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰ ì‚¬ì—…ì¥",
        "4. í‰íƒì‹œ ë…¸ì¸ë³µì§€ì‹œì„¤ ë¶„í¬",
        "5. ìœ„í—˜ì§€ìˆ˜ ë¶„ì„",
        "6. ê³µê³µ ESG ê´€ì  ì¢…í•© ì§„ë‹¨",
    ])
    # --------------------------------------------------------
    # 1. ë°ì´í„° ê°œìš”
    # --------------------------------------------------------
    with tabs[0]:
        st.subheader("ë°ì´í„° ê°œìš”")
        c1, c2, c3 = st.columns(3)
        c1.metric("ëŒ€ê¸°ì§ˆ ì›”í‰ê·  ë°ì´í„° (í–‰)", f"{len(df_air):,}")
        c2.metric("ë…¸ì¸ë³µì§€ì‹œì„¤ ìˆ˜", f"{len(df_elderly):,}")
        c3.metric("ìœ í•´í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰ ì‚¬ì—…ì¥ ìˆ˜", f"{len(df_chem):,}")

        st.markdown("#### (1) ëŒ€ê¸°ì§ˆ ì›”í‰ê·  ë°ì´í„° ì˜ˆì‹œ")
        st.dataframe(
            df_air[
                [
                    "ë„ì‹œëª…", "ì¸¡ì •ì¥ì†Œëª…", "ì¸¡ì •ì¼",
                    "PM10ì¸¡ì •ê°’(ã/ã¥)", "PM25ì¸¡ì •ê°’(ã/ã¥)",
                    "ì˜¤ì¡´ì¸¡ì •ê°’(ppm)", "ì¢…í•©ìœ„í—˜ì ìˆ˜"
                ]
            ].head(20),
            use_container_width=True,
        )

        st.markdown("#### (2) ë…¸ì¸ë³µì§€ì‹œì„¤ ë°ì´í„° ì˜ˆì‹œ")
        st.dataframe(df_elderly.head(20), use_container_width=True)

        st.markdown("#### (3) ìœ í•´í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰ ì‚¬ì—…ì¥ ë°ì´í„° ì˜ˆì‹œ")
        st.dataframe(df_chem.head(20), use_container_width=True)

        st.markdown("#### (4) ì£¼ë¯¼ë“±ë¡ ê³ ë ¹ ì¸êµ¬ ë°ì´í„° ì˜ˆì‹œ (í‰íƒì‹œ)")
        st.dataframe(df_pop_pt.head(20), use_container_width=True)

        st.caption("â€» ì¢…í•©ìœ„í—˜ì ìˆ˜: ê° ì›”/ì¸¡ì •ì†Œë³„ 6ê°œ ì˜¤ì—¼ë¬¼ì§ˆ ì ìˆ˜(1~4) ì¤‘ ìµœëŒ“ê°’")

    # --------------------------------------------------------
    # 2. ëŒ€ê¸°ì§ˆ ë¶„ì„
    # --------------------------------------------------------
    with tabs[1]:
        st.subheader("ê²½ê¸°ë„ / í‰íƒì‹œ ëŒ€ê¸°ì§ˆ ë¹„êµ ë° ì¶”ì´ ë¶„ì„")

        city_list = sorted(df_air["ë„ì‹œëª…"].unique())
        default_city_idx = city_list.index("í‰íƒì‹œ") if "í‰íƒì‹œ" in city_list else 0

        left, right = st.columns([2, 3])

        with left:
            sel_city = st.selectbox("ë„ì‹œ ì„ íƒ", city_list, index=default_city_idx)

            df_city = df_air[df_air["ë„ì‹œëª…"] == sel_city].copy()
            site_list = sorted(df_city["ì¸¡ì •ì¥ì†Œëª…"].unique())
            sel_site = st.selectbox("ì¸¡ì •ì†Œ ì„ íƒ", site_list)

            pollutant_options = list(POLLUTANT_COLS.keys())
            sel_pollutant = st.selectbox(
                "ì˜¤ì—¼ë¬¼ì§ˆ ì„ íƒ",
                pollutant_options,
                format_func=lambda x: POLLUTANT_LABELS.get(x, x),
            )

            df_site = (
                df_city[df_city["ì¸¡ì •ì¥ì†Œëª…"] == sel_site]
                .sort_values("ì¸¡ì •ì¼")
            )

            value_col = POLLUTANT_COLS[sel_pollutant]

        with right:
            st.markdown(
                f"##### [{sel_city} - {sel_site}] {POLLUTANT_LABELS.get(sel_pollutant, sel_pollutant)} ì›”ë³„ ì¶”ì´"
            )

            plot_df = df_site.set_index("ì¸¡ì •ì¼")[[value_col]]
            plot_df.columns = ["ë†ë„"]
            st.line_chart(plot_df)

        st.markdown("----")
        st.markdown("#### ë„ì‹œë³„ í‰ê·  ë†ë„ ë° ì¢…í•©ìœ„í—˜ì ìˆ˜ (ê²½ê¸°ë„ ì „ì²´)")

        st.dataframe(
            city_summary.sort_values("ì¢…í•©ìœ„í—˜ì ìˆ˜", ascending=False),
            use_container_width=True,
        )

    # --------------------------------------------------------
    # 3. í‰íƒì‹œ ìœ í•´í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰ ì‚¬ì—…ì¥
    # --------------------------------------------------------
    with tabs[2]:
        st.subheader("í‰íƒì‹œ ìœ í•´í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰ ì‚¬ì—…ì¥ í˜„í™©")

        st.metric("ì‚¬ì—…ì¥ ìˆ˜", f"{len(df_chem):,}")

        industry_all = sorted(df_chem["ì—…ì¢…ëª…"].unique())
        selected_industries = st.multiselect(
            "ì—…ì¢… í•„í„° (ì„ íƒ ì•ˆ í•˜ë©´ ì „ì²´)",
            industry_all,
        )
        if selected_industries:
            df_chem_view = df_chem[df_chem["ì—…ì¢…ëª…"].isin(selected_industries)].copy()
        else:
            df_chem_view = df_chem.copy()

        st.markdown("#### (1) ì‚¬ì—…ì¥ ìœ„ì¹˜ (ìœ„ë„/ê²½ë„ ê¸°ë°˜)")
        if {"ìœ„ë„", "ê²½ë„"}.issubset(df_chem_view.columns):
            map_df = df_chem_view.rename(columns={"ìœ„ë„": "lat", "ê²½ë„": "lon"})
            st.map(map_df[["lat", "lon"]])
        else:
            st.info("ìœ„ë„/ê²½ë„ ì •ë³´ê°€ ì—†ì–´ ì§€ë„ ì‹œê°í™”ëŠ” ìƒëµí•©ë‹ˆë‹¤.")

        st.markdown("#### (2) ìƒì„¸ í…Œì´ë¸”")
        st.dataframe(df_chem_view.reset_index(drop=True), use_container_width=True)
    # --------------------------------------------------------
    # 4. í‰íƒì‹œ ë…¸ì¸ë³µì§€ì‹œì„¤ ë¶„í¬ (ì§€ë„ ì‹œê°í™” + ì¶©ì¡±ë„ ë°ì´í„°)
    # --------------------------------------------------------
    with tabs[3]:
        st.subheader("í‰íƒì‹œ ë…¸ì¸ë³µì§€ì‹œì„¤ í˜„í™©")

        st.metric("ë…¸ì¸ë³µì§€ì‹œì„¤ ìˆ˜", f"{len(df_elderly):,}")

        # (1) ë…¸ì¸ë³µì§€ì‹œì„¤ ìœ„ì¹˜ ì§€ë„ ----------------------------------------
        st.markdown("#### (1) ë…¸ì¸ë³µì§€ì‹œì„¤ ìœ„ì¹˜ ì§€ë„")
        if {"ìœ„ë„", "ê²½ë„"}.issubset(df_elderly.columns) and not df_elderly[["ìœ„ë„", "ê²½ë„"]].isna().all().all():
            elder_map = (
                df_elderly
                .dropna(subset=["ìœ„ë„", "ê²½ë„"])
                .rename(columns={"ìœ„ë„": "lat", "ê²½ë„": "lon"})
            )
            st.map(elder_map[["lat", "lon"]])
        else:
            st.info(
                "ë…¸ì¸ë³µì§€ì‹œì„¤ ë„ë¡œëª…ì£¼ì†Œ ì§€ì˜¤ì½”ë”© ê²°ê³¼ê°€ ì—†ì–´ì„œ ì§€ë„ë¥¼ í‘œì‹œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )

        # (2) ìÂ·ë©´Â·ë™ë³„ 65ì„¸ ì´ìƒ ì¸êµ¬ ëŒ€ë¹„ ë…¸ì¸ë³µì§€ì‹œì„¤ ì¶©ì¡±ë„ -------------
        st.markdown("#### (2) ìÂ·ë©´Â·ë™ë³„ 65ì„¸ ì´ìƒ ì¸êµ¬ ëŒ€ë¹„ ë…¸ì¸ë³µì§€ì‹œì„¤ ì¶©ì¡±ë„")

        if aged_total_cols:
            # ê¸°ì¤€ ì›” ì„ íƒ
            month_label_map = {col: col.replace("_65ì„¸ì´ìƒì „ì²´", "") for col in aged_total_cols}
            month_labels = list(month_label_map.values())
            sel_label = st.selectbox(
                "ê¸°ì¤€ ì›” ì„ íƒ (65ì„¸ ì´ìƒ ì¸êµ¬)",
                month_labels,
                index=default_month_idx,
            )
            inv_month_label_map = {v: k for k, v in month_label_map.items()}
            sel_col = inv_month_label_map[sel_label]

            # í‰íƒì‹œ ìÂ·ë©´Â·ë™ë³„ 65ì„¸ ì´ìƒ ì¸êµ¬
            pop_month = (
                df_pop_pt[["ìë©´ë™", sel_col]]
                .assign(
                    ê³ ë ¹ì¸êµ¬_ìˆ˜=lambda d: d[sel_col]
                    .replace(",", "", regex=True)
                    .astype("int64")
                )[["ìë©´ë™", "ê³ ë ¹ì¸êµ¬_ìˆ˜"]]
                .groupby("ìë©´ë™")["ê³ ë ¹ì¸êµ¬_ìˆ˜"]
                .sum()
                .rename_axis("í–‰ì •ë™")
            )

            # ë…¸ì¸ë³µì§€ì‹œì„¤ ìˆ˜ (í–‰ì •ë™ ê¸°ì¤€)
            elderly_cnt_for_cov = (
                df_elderly.groupby("í–‰ì •ë™")
                .size()
                .rename("ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜")
            )

            coverage = pd.concat([elderly_cnt_for_cov, pop_month], axis=1)
            coverage["ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜"] = coverage["ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜"].fillna(0).astype(int)
            coverage["ê³ ë ¹ì¸êµ¬_ìˆ˜"] = coverage["ê³ ë ¹ì¸êµ¬_ìˆ˜"].fillna(0).astype(int)

            # 65ì„¸ ì´ìƒ 1ì²œ ëª…ë‹¹ ì‹œì„¤ ìˆ˜
            coverage["ì‹œì„¤_ì²œëª…ë‹¹"] = np.where(
                coverage["ê³ ë ¹ì¸êµ¬_ìˆ˜"] > 0,
                coverage["ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜"] / (coverage["ê³ ë ¹ì¸êµ¬_ìˆ˜"] / 1000.0),
                np.nan,
            )

            # ê²°ë¡  ì§€ë„ì—ì„œ ì“¸ ê±´ ì‹œì„¤_ì²œëª…ë‹¹ë§Œ í•„ìš”
            coverage_final = coverage[["ì‹œì„¤_ì²œëª…ë‹¹"]]

            # ì§€ë„ìš© ì¢Œí‘œ (í–‰ì •ë™ë³„ í‰ê·  ìœ„ë„/ê²½ë„)
            if {"ìœ„ë„", "ê²½ë„"}.issubset(df_elderly.columns):
                coords_cov = (
                    df_elderly
                    .dropna(subset=["ìœ„ë„", "ê²½ë„"])
                    .groupby("í–‰ì •ë™")[["ìœ„ë„", "ê²½ë„"]]
                    .mean()
                    .rename(columns={"ìœ„ë„": "lat", "ê²½ë„": "lon"})
                )
                coverage_with_coords = (
                    coverage.join(coords_cov, how="left")
                    .reset_index()
                    .rename(columns={"í–‰ì •ë™": "ìë©´ë™"})
                )
            else:
                coverage_with_coords = (
                    coverage.reset_index()
                    .rename(columns={"í–‰ì •ë™": "ìë©´ë™"})
                )

            # ì§€ë„ í‘œì‹œ (ì¢Œí‘œì™€ ì¶©ì¡±ë„ ëª¨ë‘ ìˆëŠ” í–‰ë§Œ ì‚¬ìš©)
            if {"lat", "lon"}.issubset(coverage_with_coords.columns):
                cov_for_map = coverage_with_coords.dropna(subset=["lat", "lon", "ì‹œì„¤_ì²œëª…ë‹¹"])
                if not cov_for_map.empty:
                    max_cov = float(cov_for_map["ì‹œì„¤_ì²œëª…ë‹¹"].max())
                    min_radius, max_radius = 300, 1400
                    cov_for_map["marker_radius"] = (
                        min_radius
                        + (cov_for_map["ì‹œì„¤_ì²œëª…ë‹¹"] / max_cov) * (max_radius - min_radius)
                    )

                    layer = pdk.Layer(
                        "ScatterplotLayer",
                        data=cov_for_map,
                        get_position="[lon, lat]",
                        get_radius="marker_radius",
                        get_fill_color="[0, 153, 255, 150]",
                        pickable=True,
                    )
                    view_state = pdk.ViewState(
                        latitude=float(cov_for_map["lat"].mean()),
                        longitude=float(cov_for_map["lon"].mean()),
                        zoom=10.5,
                        pitch=0,
                    )
                    st.pydeck_chart(
                        pdk.Deck(
                            layers=[layer],
                            initial_view_state=view_state,
                            tooltip={
                                "text": "ìÂ·ë©´Â·ë™: {ìë©´ë™}\\n"
                                        "65ì„¸ ì´ìƒ ì¸êµ¬: {ê³ ë ¹ì¸êµ¬_ìˆ˜}ëª…\\n"
                                        "ë…¸ì¸ë³µì§€ì‹œì„¤ ìˆ˜: {ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜}ê°œ\\n"
                                        "ì‹œì„¤ ìˆ˜ (ì²œ ëª…ë‹¹): {ì‹œì„¤_ì²œëª…ë‹¹:.2f}"
                            },
                        )
                    )
                    st.caption(
                        f"â€» ê¸°ì¤€ ì›”: **{sel_label}**, 65ì„¸ ì´ìƒ 1ì²œ ëª…ë‹¹ ì‹œì„¤ ìˆ˜ê°€ í´ìˆ˜ë¡ "
                        "ë…¸ì¸ë³µì§€ ì¸í”„ë¼ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì˜ ê°–ì¶°ì§„ ì§€ì—­ì…ë‹ˆë‹¤."
                    )

            # âœ… ì§€ì˜¤ì½”ë”© + ì¶©ì¡±ë„ ê²°ê³¼ ë°ì´í„° í…Œì´ë¸” í•­ìƒ ë³´ì—¬ì£¼ê¸°
            st.markdown("#### (3) ìÂ·ë©´Â·ë™ë³„ ë…¸ì¸ë³µì§€ì‹œì„¤ ì¶©ì¡±ë„ ë°ì´í„°")
            cols_to_show = ["ìë©´ë™", "ê³ ë ¹ì¸êµ¬_ìˆ˜", "ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜", "ì‹œì„¤_ì²œëª…ë‹¹"]

            st.dataframe(
                coverage_with_coords[cols_to_show].sort_values(
                    "ì‹œì„¤_ì²œëª…ë‹¹", ascending=False
                ),
                use_container_width=True,
            )

        else:
            st.info("ì£¼ë¯¼ë“±ë¡ ì¸êµ¬ í†µê³„ ë°ì´í„°ì—ì„œ '65ì„¸ì´ìƒì „ì²´' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # (4) ë„ë¡œëª…ì£¼ì†Œ ê²€ìƒ‰ --------------------------------------------
        st.markdown("#### (4) ë„ë¡œëª…ì£¼ì†Œ ê²€ìƒ‰")
        addr_query = st.text_input("ë„ë¡œëª…ì£¼ì†Œì— í¬í•¨ë  í‚¤ì›Œë“œ (ì˜ˆ: ê³ ë•, ì•ˆì¤‘, ì²­ë¶ ë“±)")
        df_elderly_view = df_elderly.copy()
        if addr_query:
            df_elderly_view = df_elderly_view[
                df_elderly_view["ë„ë¡œëª…ì£¼ì†Œ"].str.contains(addr_query, na=False)
            ]

        st.dataframe(df_elderly_view.reset_index(drop=True), use_container_width=True)

    # --------------------------------------------------------
    # 5. ìœ„í—˜ì§€ìˆ˜ ë¶„ì„ (ìÂ·ë©´Â·ë™ ë‹¨ìœ„)
    # --------------------------------------------------------
    with tabs[4]:
        st.subheader("í‰íƒì‹œ ìÂ·ë©´Â·ë™ë³„ í™˜ê²½ ìœ„í—˜ì§€ìˆ˜ ë¶„ì„")

        # (1) í‰íƒì‹œ ëŒ€ê¸°í™˜ê²½ ì§„ë‹¨í‰ê°€ì‹œìŠ¤í…œ ì •ë³´ ---------------------------
        st.markdown("#### (1) í‰íƒì‹œ ëŒ€ê¸°í™˜ê²½ ì§„ë‹¨í‰ê°€ì‹œìŠ¤í…œ ì •ë³´")
        st.write(f"- ì§€ì—­ êµ¬ë¶„: **{region_row['ì§€ì—­']}**")
        st.write(f"- ì‹œêµ°êµ¬ëª…: **{region_row['ì‹œêµ°êµ¬ëª…']}**")
        st.write(f"- ì§€í˜• ì½”ë“œ: **{region_row['ì§€í˜•']}**")

         # (2) í‰íƒì‹œ ìÂ·ë©´Â·ë™ë³„ ë…¸ì¸ë³µì§€ì‹œì„¤ Â· ìœ í•´í™”í•™ì‚¬ì—…ì¥ Â· ëŒ€ê¸°ì§ˆ ìœ„í—˜ ì§€ìˆ˜ Â· ìœ„í—˜ ì§€ìˆ˜
        st.markdown("#### (2) í‰íƒì‹œ ìÂ·ë©´Â·ë™ë³„ ë…¸ì¸ë³µì§€ì‹œì„¤ Â· ìœ í•´í™”í•™ì‚¬ì—…ì¥ Â· ëŒ€ê¸°ì§ˆ ìœ„í—˜ ì§€ìˆ˜ Â· ìœ„í—˜ ì§€ìˆ˜")
        st.caption(
            "ëŒ€ê¸°ì§ˆ ìœ„í—˜ ì§€ìˆ˜ = pyeongtaek_CAI_index.csvì˜ CAI_Index ê°’, "
            "ìœ„í—˜ ì§€ìˆ˜ = 0.3 Ã— ìœ í•´í™”í•™ì‚¬ì—…ì¥ ìˆ˜ + 0.7 Ã— ëŒ€ê¸°ì§ˆ ìœ„í—˜ ì§€ìˆ˜"
        )

        risk_table = (
            local_risk[["ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜", "ìœ í•´í™”í•™ì‚¬ì—…ì¥_ìˆ˜", "ëŒ€ê¸°ì§ˆìœ„í—˜ì§€ìˆ˜", "ìœ„í—˜ì§€ìˆ˜"]]
            .reset_index()
            .rename(
                columns={
                    "í–‰ì •ë™": "ìÂ·ë©´Â·ë™",
                    "ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜": "ë…¸ì¸ë³µì§€ì‹œì„¤ ìˆ˜",
                    "ìœ í•´í™”í•™ì‚¬ì—…ì¥_ìˆ˜": "ìœ í•´í™”í•™ì‚¬ì—…ì¥ ìˆ˜",
                    "ëŒ€ê¸°ì§ˆìœ„í—˜ì§€ìˆ˜": "ëŒ€ê¸°ì§ˆ ìœ„í—˜ ì§€ìˆ˜",
                    "ìœ„í—˜ì§€ìˆ˜": "ìœ„í—˜ ì§€ìˆ˜",
                }
            )
        )

        st.dataframe(risk_table, use_container_width=True)

        # (3) í‰íƒì‹œ ìÂ·ë©´Â·ë™ë³„ ìœ„í—˜ ì§€ìˆ˜ ì§€ë„ ------------------------------
        st.markdown("#### (3) í‰íƒì‹œ ìÂ·ë©´Â·ë™ë³„ ìœ„í—˜ ì§€ìˆ˜ ì§€ë„")

        if {"ìœ„ë„", "ê²½ë„"}.issubset(local_risk_map.columns) and not local_risk_map["ìœ„ë„"].isna().all():
            risk_map_df = local_risk_map.dropna(subset=["ìœ„ë„", "ê²½ë„"]).reset_index()
            risk_map_df = risk_map_df.rename(
                columns={"í–‰ì •ë™": "ìë©´ë™", "ìœ„ë„": "lat", "ê²½ë„": "lon"}
            )

            max_risk = float(risk_map_df["ìœ„í—˜ì§€ìˆ˜"].max())
            min_radius = 300
            max_radius = 1300

            risk_map_df["marker_radius"] = (
                min_radius
                + (risk_map_df["ìœ„í—˜ì§€ìˆ˜"] / max_risk) * (max_radius - min_radius)
            )

            layer = pdk.Layer(
                "ScatterplotLayer",
                data=risk_map_df,
                get_position="[lon, lat]",
                get_radius="marker_radius",
                get_fill_color="[255, 0, 0, 140]",
                pickable=True,
            )

            view_state = pdk.ViewState(
                latitude=float(risk_map_df["lat"].mean()),
                longitude=float(risk_map_df["lon"].mean()),
                zoom=10.5,
                pitch=0,
            )

            st.pydeck_chart(
                pdk.Deck(
                    layers=[layer],
                    initial_view_state=view_state,
                    tooltip={"text": "ìÂ·ë©´Â·ë™: {ìë©´ë™}\nìœ„í—˜ì§€ìˆ˜: {ìœ„í—˜ì§€ìˆ˜}"},
                )
            )

            st.caption(
                "â€» ìœ„í—˜ì§€ìˆ˜ ì§€ë„ëŠ” ë…¸ì¸ë³µì§€ì‹œì„¤Â·ìœ í•´í™”í•™ì‚¬ì—…ì¥ ì£¼ì†Œë¥¼ ì§€ì˜¤ì½”ë”©í•˜ì—¬ ì–»ì€ ì¢Œí‘œ(ìœ„ë„Â·ê²½ë„)ë¥¼ "
                "ìÂ·ë©´Â·ë™ë³„ë¡œ í‰ê· ë‚¸ ìœ„ì¹˜ì— í‘œì‹œí•œ ê²ƒì…ë‹ˆë‹¤."
            )
        else:
            st.info(
                "ìœ„í—˜ì§€ìˆ˜ ì§€ë„ë¥¼ í‘œì‹œí•˜ë ¤ë©´ ìÂ·ë©´Â·ë™ë³„ ìœ„ë„/ê²½ë„ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "ë…¸ì¸ë³µì§€ì‹œì„¤ ë° ìœ í•´í™”í•™ë¬¼ì§ˆ ì‚¬ì—…ì¥ ë„ë¡œëª…ì£¼ì†Œë¥¼ ì§€ì˜¤ì½”ë”©í•´ 'ìœ„ë„', 'ê²½ë„' ì—´ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”."
            )

        # (4) ì‹œê°ìë£Œ ê¸°ë°˜ ê²°ë¡  ìš”ì•½ ---------------------------------------
        st.markdown("#### (4) ì‹œê°ìë£Œ ê¸°ë°˜ ê²°ë¡  ìš”ì•½")

        top_risky = local_risk.sort_values("ìœ„í—˜ì§€ìˆ˜", ascending=False).head(3).index.tolist()
        top_safe = local_risk.sort_values("ìœ„í—˜ì§€ìˆ˜", ascending=True).head(3).index.tolist()

        st.markdown(
            f"""
            - **ìœ„í—˜ ì§€ìˆ˜ ìƒìœ„ 3ê°œ ìÂ·ë©´Â·ë™**: {", ".join(top_risky)}  
              â†’ ìœ í•´í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰ ì‚¬ì—…ì¥ ìˆ˜(ê°€ì¤‘ì¹˜ 0.3)ì™€ ëŒ€ê¸°ì§ˆ ìœ„í—˜ ì§€ìˆ˜(ê°€ì¤‘ì¹˜ 0.7)ê°€ ëª¨ë‘ ë†’ì€ **ë³µí•© í™˜ê²½ ì·¨ì•½ ì§€ì—­**ì…ë‹ˆë‹¤.  
                Â· ì‹ ê·œ ë…¸ì¸ë³µì§€ì‹œì„¤ ì…ì§€ ì„ ì • ì‹œì—ëŠ” ì´ë“¤ ì§€ì—­ì€ ì§€ì–‘í•˜ê³ ,  
                  ê¸°ì¡´ ì‹œì„¤ì— ëŒ€í•´ì„œëŠ” ê³µê¸°ì§ˆ ê°œì„ , ìœ í•´ë¬¼ì§ˆ ê´€ë¦¬, ì‹¤ë‚´ í™˜ê¸°Â·í•„í„°ë§ ê°•í™” ë“± **í™˜ê²½ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì¤‘ì‹¬ ì „ëµ**ì´ í•„ìš”í•©ë‹ˆë‹¤.  

            - **ìœ„í—˜ ì§€ìˆ˜ í•˜ìœ„ 3ê°œ ìÂ·ë©´Â·ë™**: {", ".join(top_safe)}  
              â†’ ëŒ€ê¸°ì§ˆì´ ìƒëŒ€ì ìœ¼ë¡œ ì–‘í˜¸í•˜ê±°ë‚˜ ìœ í•´í™”í•™ì‚¬ì—…ì¥ ë°€ì§‘ë„ê°€ ë‚®ì€ **ìƒëŒ€ì  ì•ˆì „ ì§€ì—­**ìœ¼ë¡œ í•´ì„ë©ë‹ˆë‹¤.  
                Â· ì¶”ê°€ ë…¸ì¸ë³µì§€ì‹œì„¤ ê³µê¸‰ì´ í•„ìš”í•  ê²½ìš°, ìš°ì„ ì ìœ¼ë¡œ ê²€í† í•  ìˆ˜ ìˆëŠ” í›„ë³´ì§€ì´ë©°,  
                  ë™ì‹œì— **ìƒí™œ í¸ì˜Â·ì ‘ê·¼ì„±Â·ì„œë¹„ìŠ¤ í’ˆì§ˆ** ì¸¡ë©´ì—ì„œì˜ ì„¸ë°€í•œ ê°œì„ ì´ ì í•©í•œ ì§€ì—­ì…ë‹ˆë‹¤.
            """
        )

        st.markdown(
            f"""
            - **ì·¨ì•½ ì§€ì—­(ìœ„í—˜ì§€ìˆ˜ ìƒìœ„ 3)**: {", ".join(top_risky)}  
              â†’ ìœ í•´í™”í•™ë¬¼ì§ˆ ì·¨ê¸‰ì‚¬ì—…ì¥ ë°€ì§‘ë„ì™€ ëŒ€ê¸°ì§ˆ(CAI)ì´ ìƒëŒ€ì ìœ¼ë¡œ ë‚˜ìœ ì§€ì—­ìœ¼ë¡œ,  
                ë™ì‹œì— ë…¸ì¸ë³µì§€ì‹œì„¤ì´ ë¶€ì¡±í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ **ìš°ì„  ê´€ë¦¬ ëŒ€ìƒ ê¶Œì—­**ìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

            - **ìƒëŒ€ì ìœ¼ë¡œ ì–‘í˜¸í•œ ì§€ì—­(ìœ„í—˜ì§€ìˆ˜ í•˜ìœ„ 3)**: {", ".join(top_safe)}  
              â†’ ë…¸ì¸ë³µì§€ì‹œì„¤ì´ ìƒëŒ€ì ìœ¼ë¡œ ì¶©ë¶„í•˜ê±°ë‚˜ ìœ í•´í™”í•™ì‚¬ì—…ì¥ ë°€ì§‘ë„ê°€ ë‚®ì€ ì§€ì—­ìœ¼ë¡œ,  
                ì‹ ê·œ ê³µê¸‰ë³´ë‹¤ëŠ” **ê¸°ì¡´ ì‹œì„¤ì˜ ì§ˆì  ê°œì„ ê³¼ ì„œë¹„ìŠ¤ ê³ ë„í™”** ì¤‘ì‹¬ì˜ ì „ëµì´ ì í•©í•©ë‹ˆë‹¤.  
            """
        )
        # --------------------------------------------------------
    # 6. ê³µê³µ ESG ê´€ì  ì¢…í•© ì§„ë‹¨  (ì§€ë„ + ê²°ë¡ )
    # --------------------------------------------------------
    with tabs[5]:
        st.subheader("ê³µê³µ ESG ê´€ì ì—ì„œ ë³¸ í‰íƒì‹œ ë…¸ì¸ë³µì§€ì‹œì„¤ ì…ì§€ ì „ëµ")

        # ğŸ‘‰ ìÂ·ë©´Â·ë™ë³„ í™˜ê²½ ìœ„í—˜(local_risk_map) + ë…¸ì¸ë³µì§€ì‹œì„¤ ì¶©ì¡±ë„(coverage_final) ê²°í•©
        #   - index: í–‰ì •ë™
        #   - í•„ìš”í•œ ì»¬ëŸ¼: ì‹œì„¤_ì²œëª…ë‹¹, ìœ„í—˜ì§€ìˆ˜, ìœ„ë„, ê²½ë„
        emd_final = local_risk_map.join(coverage_final, how="left")
        emd_final = emd_final.dropna(subset=["ì‹œì„¤_ì²œëª…ë‹¹", "ìœ„í—˜ì§€ìˆ˜", "ìœ„ë„", "ê²½ë„"])

        # (1) í˜„ì¬ ì¢…í•©ìœ„í—˜ì§€ìˆ˜ / ê²½ê¸°ë„ í‰ê·  / í‰íƒì‹œ PM2.5
        col1, col2, col3 = st.columns(3)
        col1.metric(
            "í‰íƒì‹œ í‰ê·  ì¢…í•©ìœ„í—˜ì ìˆ˜ (1~4)",
            f"{pyeongtaek_risk:.2f}",
        )
        col2.metric(
            "ê²½ê¸°ë„ í‰ê·  ì¢…í•©ìœ„í—˜ì ìˆ˜",
            f"{gyeonggi_mean_risk:.2f}",
            delta=f"{pyeongtaek_risk - gyeonggi_mean_risk:+.2f}",
        )
        col3.metric(
            "í‰íƒì‹œ í‰ê·  PM2.5 (ã/ã¥)",
            f"{pyeongtaek_row['PM25ì¸¡ì •ê°’(ã/ã¥)']:.1f}",
        )

        # ê³µí†µ ë°ì´í„°(ìÂ·ë©´Â·ë™ë³„ ìœ„í—˜ì§€ìˆ˜ + ì¢Œí‘œ)
        has_coords = {"ìœ„ë„", "ê²½ë„"}.issubset(local_risk_map.columns) and not local_risk_map["ìœ„ë„"].isna().all()
        if has_coords:
            base_geo = local_risk_map.dropna(subset=["ìœ„ë„", "ê²½ë„"]).reset_index()
            base_geo = base_geo.rename(
                columns={"í–‰ì •ë™": "ìë©´ë™", "ìœ„ë„": "lat", "ê²½ë„": "lon"}
            )
        else:
            base_geo = None

        # (2) í™˜ê²½ ìœ„í—˜ ì§€ë„ (ë¹¨ê°„ìƒ‰ ì›)
        st.markdown("#### (2) í™˜ê²½ ìœ„í—˜ ì§€ë„ (ìÂ·ë©´Â·ë™ë³„ í™˜ê²½ ìœ„í—˜ì§€ìˆ˜)")
        if has_coords and not base_geo.empty:
            max_risk = float(base_geo["ìœ„í—˜ì§€ìˆ˜"].max())
            min_radius = 300
            max_radius = 1300

            base_geo["marker_radius"] = (
                min_radius
                + (base_geo["ìœ„í—˜ì§€ìˆ˜"] / max_risk) * (max_radius - min_radius)
            )

            env_layer = pdk.Layer(
                "ScatterplotLayer",
                data=base_geo,
                get_position="[lon, lat]",
                get_radius="marker_radius",
                get_fill_color="[255, 0, 0, 140]",  # ë¹¨ê°„ìƒ‰
                pickable=True,
            )

            env_view = pdk.ViewState(
                latitude=float(base_geo["lat"].mean()),
                longitude=float(base_geo["lon"].mean()),
                zoom=10.5,
                pitch=0,
            )

            st.pydeck_chart(
                pdk.Deck(
                    layers=[env_layer],
                    initial_view_state=env_view,
                    tooltip={"text": "ìÂ·ë©´Â·ë™: {ìë©´ë™}\nìœ„í—˜ì§€ìˆ˜: {ìœ„í—˜ì§€ìˆ˜}"},
                )
            )
        else:
            st.info("í™˜ê²½ ìœ„í—˜ ì§€ë„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ìÂ·ë©´Â·ë™ ì¢Œí‘œ(ìœ„ë„/ê²½ë„)ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # (3) ì²­ì • êµ¬ì—­ ì§€ë„ (ì´ˆë¡ìƒ‰ ì›)
        st.markdown("#### (3) ì²­ì • êµ¬ì—­ ì§€ë„ (ìœ„í—˜ì§€ìˆ˜ í•˜ìœ„ ì§€ì—­)")
        if has_coords and not base_geo.empty:
            clean_threshold = base_geo["ìœ„í—˜ì§€ìˆ˜"].quantile(0.30)
            clean_geo = base_geo[base_geo["ìœ„í—˜ì§€ìˆ˜"] <= clean_threshold]

            if not clean_geo.empty:
                clean_layer = pdk.Layer(
                    "ScatterplotLayer",
                    data=clean_geo,
                    get_position="[lon, lat]",
                    get_radius=900,
                    get_fill_color="[0, 200, 0, 180]",  # ì´ˆë¡ìƒ‰
                    pickable=True,
                )

                clean_view = pdk.ViewState(
                    latitude=float(clean_geo["lat"].mean()),
                    longitude=float(clean_geo["lon"].mean()),
                    zoom=10.5,
                    pitch=0,
                )

                st.pydeck_chart(
                    pdk.Deck(
                        layers=[clean_layer],
                        initial_view_state=clean_view,
                        tooltip={"text": "ìÂ·ë©´Â·ë™: {ìë©´ë™}\nìœ„í—˜ì§€ìˆ˜: {ìœ„í—˜ì§€ìˆ˜}"},
                    )
                )
            else:
                st.info("ìœ„í—˜ì§€ìˆ˜ê°€ ë‚®ì€(ì²­ì •) êµ¬ì—­ì´ í†µê³„ì ìœ¼ë¡œ ì¶©ë¶„íˆ ë‚˜ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì²­ì • êµ¬ì—­ ì§€ë„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ìÂ·ë©´Â·ë™ ì¢Œí‘œ(ìœ„ë„/ê²½ë„)ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # (4) ë…¸ì¸ë³µì§€ì‹œì„¤ ìœ„ì¹˜ ì§€ë„
        st.markdown("#### (4) ë…¸ì¸ë³µì§€ì‹œì„¤ ìœ„ì¹˜ ì§€ë„")
        if {"ìœ„ë„", "ê²½ë„"}.issubset(df_elderly.columns):
            elder_geo = df_elderly.dropna(subset=["ìœ„ë„", "ê²½ë„"]).rename(
                columns={"ìœ„ë„": "lat", "ê²½ë„": "lon"}
            )
            st.map(elder_geo[["lat", "lon"]])
        else:
            st.info(
                "ë…¸ì¸ë³µì§€ì‹œì„¤ ë°ì´í„°ì— ìœ„ë„/ê²½ë„ ì—´ì´ ì—†ìŠµë‹ˆë‹¤. "
                "ë„ë¡œëª…ì£¼ì†Œë¥¼ ì§€ì˜¤ì½”ë”©í•´ 'ìœ„ë„', 'ê²½ë„' ì—´ì„ ì¶”ê°€í•˜ë©´ ì§€ë„ ì‹œê°í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )

        # (5) ê²°ë¡  ì§€ë„: ê´€ë¦¬ ì§‘ì¤‘ / ì‹œì„¤ ì¦ì„¤ ëŒ€ìƒ êµ¬ì—­
        st.markdown("#### (5) ê²°ë¡  ì§€ë„: ë…¸ì¸ë³µì§€ì‹œì„¤ê³¼ í™˜ê²½ ë¦¬ìŠ¤í¬ë¥¼ í•¨ê»˜ ë³¸ ìš°ì„ Â·ì¦ì„¤ ëŒ€ìƒ êµ¬ì—­")

        if not emd_final.empty:
            # emd_final: í–‰ì •ë™ index + [ë…¸ì¸ë³µì§€ì‹œì„¤_ìˆ˜, ìœ í•´í™”í•™ì‚¬ì—…ì¥_ìˆ˜, ëŒ€ê¸°ì§ˆìœ„í—˜ì§€ìˆ˜, ìœ„í—˜ì§€ìˆ˜, ìœ„ë„, ê²½ë„, ì‹œì„¤_ì²œëª…ë‹¹]
            emd_geo = (
                emd_final
                .reset_index()
                .rename(columns={"í–‰ì •ë™": "ìë©´ë™", "ìœ„ë„": "lat", "ê²½ë„": "lon"})
                .dropna(subset=["lat", "lon"])
            )

            # 1) ê¸°ì¤€ì„  ê³„ì‚°
            risk_low_thr  = emd_geo["ìœ„í—˜ì§€ìˆ˜"].median()        # â€˜ì²­ì •â€™ ê¸°ì¤€ (ìœ„í—˜ ì§€ìˆ˜ ë‚®ì€ ìª½)
            risk_high_thr = emd_geo["ìœ„í—˜ì§€ìˆ˜"].quantile(0.75)  # â€˜ê³ ìœ„í—˜â€™ ê¸°ì¤€
            cov_low_thr   = emd_geo["ì‹œì„¤_ì²œëª…ë‹¹"].quantile(0.25)  # ì‹œì„¤ ë¶€ì¡± ê¸°ì¤€ (í•˜ìœ„ 25%)
            cov_high_thr  = emd_geo["ì‹œì„¤_ì²œëª…ë‹¹"].quantile(0.75)  # ì‹œì„¤ ì¶©ë¶„ ê¸°ì¤€ (ìƒìœ„ 25%)

            # 1-1) ì‹œì„¤ ì¦ì„¤ í›„ë³´(íŒŒë€ ì›)
            #  - ì¡°ê±´: ìœ„í—˜ì§€ìˆ˜ â‰¤ ì¤‘ìœ„ìˆ˜(ìƒëŒ€ì ìœ¼ë¡œ ì²­ì •) AND ì‹œì„¤_ì²œëª…ë‹¹ â‰¤ í•˜ìœ„ 25% (ì‹œì„¤ ë¶€ì¡±)
            expand_candidates = (
                emd_geo[
                    (emd_geo["ìœ„í—˜ì§€ìˆ˜"] <= risk_low_thr)
                    & (emd_geo["ì‹œì„¤_ì²œëª…ë‹¹"] <= cov_low_thr)
                ]
                .sort_values("ì‹œì„¤_ì²œëª…ë‹¹")      # ì‹œì„¤_ì²œëª…ë‹¹ ë‚®ì€ ìˆœ â†’ 1ìˆœìœ„
                .head(3)
                .copy()
            )
            expand_candidates["expand_rank"] = np.arange(1, len(expand_candidates) + 1)

            # 1-2) ê´€ë¦¬ ì§‘ì¤‘ í›„ë³´(ë¹¨ê°„ ì›)
            #  - ì¡°ê±´: ìœ„í—˜ì§€ìˆ˜ â‰¥ ìƒìœ„ 25% AND ì‹œì„¤_ì²œëª…ë‹¹ â‰¥ ìƒìœ„ 25% (ì‹œì„¤ì€ ë§ì€ë° í™˜ê²½ì´ ë‚˜ì¨)
            focus_candidates = (
                emd_geo[
                    (emd_geo["ìœ„í—˜ì§€ìˆ˜"] >= risk_high_thr)
                    & (emd_geo["ì‹œì„¤_ì²œëª…ë‹¹"] >= cov_high_thr)
                ]
                .sort_values("ìœ„í—˜ì§€ìˆ˜", ascending=False)  # ìœ„í—˜ì§€ìˆ˜ ë†’ì€ ìˆœ â†’ 1ìˆœìœ„
                .head(3)
                .copy()
            )
            focus_candidates["focus_rank"] = np.arange(1, len(focus_candidates) + 1)

            # 2) ì› í¬ê¸° ì„¤ì •
            #   - íŒŒë€ ì›: ì¦ì„¤ ìš°ì„ ìˆœìœ„ 1 â†’ ê°€ì¥ í° ì›, 2Â·3ìœ„ëŠ” ì ì  ì‘ê²Œ
            #   - ë¹¨ê°„ ì›: ê´€ë¦¬ ìš°ì„ ìˆœìœ„ 1 â†’ ê°€ì¥ í° ì›, 2Â·3ìœ„ëŠ” ì ì  ì‘ê²Œ
            blue_radius = {1: 1300, 2: 1000, 3: 700}
            red_radius  = {1: 1500, 2: 1150, 3: 800}

            expand_candidates["marker_radius_blue"] = expand_candidates["expand_rank"].map(blue_radius)
            focus_candidates["marker_radius_red"]   = focus_candidates["focus_rank"].map(red_radius)

            # 3) ë ˆì´ì–´ êµ¬ì„± (ë°°ê²½ + íŒŒë€ ì› + ë¹¨ê°„ ì›)
            layers = [
                # ì „ì²´ ìÂ·ë©´Â·ë™ ë°°ê²½ (ì˜…ì€ íšŒìƒ‰ ì )
                pdk.Layer(
                    "ScatterplotLayer",
                    data=emd_geo,
                    get_position="[lon, lat]",
                    get_radius=250,
                    get_fill_color="[120, 120, 120, 60]",
                    pickable=False,
                )
            ]

            if not expand_candidates.empty:
                layers.append(
                    pdk.Layer(
                        "ScatterplotLayer",
                        data=expand_candidates,
                        get_position="[lon, lat]",
                        get_radius="marker_radius_blue",
                        get_fill_color="[0, 153, 255, 220]",  # íŒŒë‘
                        pickable=True,
                    )
                )

            if not focus_candidates.empty:
                layers.append(
                    pdk.Layer(
                        "ScatterplotLayer",
                        data=focus_candidates,
                        get_position="[lon, lat]",
                        get_radius="marker_radius_red",
                        get_fill_color="[255, 0, 0, 220]",  # ë¹¨ê°•
                        pickable=True,
                    )
                )

            view_state = pdk.ViewState(
                latitude=float(emd_geo["lat"].mean()),
                longitude=float(emd_geo["lon"].mean()),
                zoom=10.5,
                pitch=0,
            )

            st.pydeck_chart(
                pdk.Deck(
                    layers=layers,
                    initial_view_state=view_state,
                    tooltip={
                        "text": "ìÂ·ë©´Â·ë™: {ìë©´ë™}\n"
                                "ì‹œì„¤ ìˆ˜ (ì²œ ëª…ë‹¹): {ì‹œì„¤_ì²œëª…ë‹¹:.2f}\n"
                                "ìœ„í—˜ì§€ìˆ˜: {ìœ„í—˜ì§€ìˆ˜:.2f}"
                    },
                )
            )

            # (6) ê²°ë¡  ìš”ì•½ (í‘œ)
            st.markdown("#### (6) ê²°ë¡  ìš”ì•½ (í‘œ)")
            col_left, col_right = st.columns(2)

            with col_left:
                st.markdown("**ê´€ë¦¬ ì§‘ì¤‘ ëŒ€ìƒ êµ¬ì—­ (ë³µì§€ì‹œì„¤ ë§ê³  ëŒ€ê¸°ì§ˆì´ ë‚˜ìœ ê³³)**")
                if focus_candidates.empty:
                    st.write("ì„ ì •ëœ ê´€ë¦¬ ì§‘ì¤‘ ëŒ€ìƒ êµ¬ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    focus_table = focus_candidates[
                        ["ìë©´ë™", "ì‹œì„¤_ì²œëª…ë‹¹", "ìœ„í—˜ì§€ìˆ˜"]
                    ].rename(
                        columns={
                            "ìë©´ë™": "ìÂ·ë©´Â·ë™",
                            "ì‹œì„¤_ì²œëª…ë‹¹": "ì‹œì„¤ ìˆ˜ (ì²œ ëª…ë‹¹)",
                            "ìœ„í—˜ì§€ìˆ˜": "í™˜ê²½ ìœ„í—˜ ì§€ìˆ˜",
                        }
                    )
                    st.dataframe(focus_table, use_container_width=True)

            with col_right:
                st.markdown("**ì‹œì„¤ ì¦ì„¤ ëŒ€ìƒ êµ¬ì—­ (ì²­ì •í•˜ì§€ë§Œ ë³µì§€ì‹œì„¤ì´ ë¶€ì¡±í•œ ê³³)**")
                if expand_candidates.empty:
                    st.write("ì„ ì •ëœ ì‹œì„¤ ì¦ì„¤ ëŒ€ìƒ êµ¬ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    expand_table = expand_candidates[
                        ["ìë©´ë™", "ì‹œì„¤_ì²œëª…ë‹¹", "ìœ„í—˜ì§€ìˆ˜"]
                    ].rename(
                        columns={
                            "ìë©´ë™": "ìÂ·ë©´Â·ë™",
                            "ì‹œì„¤_ì²œëª…ë‹¹": "ì‹œì„¤ ìˆ˜ (ì²œ ëª…ë‹¹)",
                            "ìœ„í—˜ì§€ìˆ˜": "í™˜ê²½ ìœ„í—˜ ì§€ìˆ˜",
                        }
                    )
                    st.dataframe(expand_table, use_container_width=True)

        else:
            st.info(
                "ë…¸ì¸ë³µì§€ì‹œì„¤ ì¶©ì¡±ë„(ì‹œì„¤_ì²œëª…ë‹¹)ì™€ ìœ„í—˜ì§€ìˆ˜, ì¢Œí‘œê°€ ëª¨ë‘ ìˆëŠ” ìÂ·ë©´Â·ë™ì´ ì—†ì–´ ê²°ë¡  ì§€ë„ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )


if __name__ == "__main__":
    main()
